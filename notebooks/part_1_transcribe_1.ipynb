{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai-whisper moviepy"
      ],
      "metadata": {
        "id": "H5wy0fYyouOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTiP5hhNouQ4",
        "outputId": "4b160d49-97fe-4614-e716-3a2208e0dbd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/path/to/data\""
      ],
      "metadata": {
        "id": "E80eBBjupCpf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe"
      ],
      "metadata": {
        "id": "tV-_3Ilppv0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Whisper"
      ],
      "metadata": {
        "id": "aeHQrERZ1iJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model('large-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KBIiL5NbDlR",
        "outputId": "7027c3ab-42b6-4b9c-c246-d83413a667de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:26<00:00, 114MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(os.path.join(data_dir, 'encounter.m4v'))"
      ],
      "metadata": {
        "id": "_dNK6nstZ_G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax-jVPUcouTS",
        "outputId": "96ac24f6-fb8d-47a7-c8fa-e9e62edb4585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(data_dir, 'video_transcription.json'), 'wt', encoding='utf-8') as f:\n",
        "  json.dump(result, f)"
      ],
      "metadata": {
        "id": "p1lbmk44qg2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Speaker Diarization"
      ],
      "metadata": {
        "id": "cuVAfLhzs033"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def whisper_results_to_srt(whisper_results):\n",
        "    srt_content = \"\"\n",
        "    for i, segment in enumerate(whisper_results['segments'], start=1):\n",
        "        # Convert start and end times from seconds to SRT timestamp format\n",
        "        start_time = format_timestamp_srt(segment['start'])\n",
        "        end_time = format_timestamp_srt(segment['end'])\n",
        "        text = segment['text']\n",
        "\n",
        "        # Append formatted segment to SRT content\n",
        "        srt_content += f\"{i}\\n{start_time} --> {end_time}\\n{text}\\n\\n\"\n",
        "\n",
        "    return srt_content"
      ],
      "metadata": {
        "id": "i9H4qPFyRlj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_timestamp_srt(seconds):\n",
        "    \"\"\"Converts seconds to SRT timestamp format (HH:MM:SS,mmm)\"\"\"\n",
        "    hours, remainder = divmod(seconds, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    milliseconds = (seconds - int(seconds)) * 1000\n",
        "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02},{int(milliseconds):03}\""
      ],
      "metadata": {
        "id": "MDU-BoR2nd2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_content = whisper_results_to_srt(result)"
      ],
      "metadata": {
        "id": "RPC-_1UenbyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data\n",
        "srt_file = \"video.srt\""
      ],
      "metadata": {
        "id": "Z602zMCqqhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(srt_file, 'wt', encoding='utf-8') as file:\n",
        "    file.write(srt_content)"
      ],
      "metadata": {
        "id": "g0D6m9ZeRMQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp srt_file \"{data_dir}\""
      ],
      "metadata": {
        "id": "-QFO2wrD4Zlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT-4 prompt**"
      ],
      "metadata": {
        "id": "L-wcPePs4m2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community langchain-openai langchain-anthropic"
      ],
      "metadata": {
        "id": "bl4vnY4-tiLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.environ['OPENAI_API_KEY'] = ''\n",
        "#os.environ['ANTHROPIC_API_KEY'] = ''"
      ],
      "metadata": {
        "id": "tbDfKkAg4fmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "nwXJXsWNrsuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"\n",
        "## HERE IS THE EXAMPLE ##\n",
        "Srt file input is enclosed in backticks:\n",
        "```\n",
        "1\n",
        "00:00:00,000 --> 00:00:01,500\n",
        " My name is Dr. House.\n",
        "\n",
        "2\n",
        "00:00:01,500 --> 00:00:02,700\n",
        " And this is Nelson, correct?\n",
        "\n",
        "3\n",
        "00:00:02,700 --> 00:00:03,200\n",
        " Yes.\n",
        "\n",
        "4\n",
        "00:00:03,200 --> 00:00:04,500\n",
        " Very nice to meet you.\n",
        "\n",
        "5\n",
        "00:00:04,500 --> 00:00:05,500\n",
        " Nice to meet you.\n",
        "\n",
        "6\n",
        "00:00:05,500 --> 00:00:11,500\n",
        " I understand I read outside some information that you're here for your son, who's 26 months old.```\n",
        "\n",
        "ANSWER:\n",
        "1. Doctor\n",
        "2. Doctor\n",
        "3. Patient\n",
        "4. Doctor\n",
        "5. Patient\n",
        "6. Doctor\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l3Hgip_ZvCLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_message = \"\"\"You are a helpful assistant for medical english and doctor patient communication.\n",
        "I will provide a transcript text (in the form of srt file) from a doctor patient encounter recorded in an OSCE exam.\n",
        "However, this transcript does not separate the doctor and the patient.\n",
        "Can you please identify the speaker in each transcript segment as doctor or patient?\n",
        "\"\"\" + example + \"\"\"\\nCan you please evaluate the following srt: \\n{srt}\"\"\""
      ],
      "metadata": {
        "id": "rXk76TWDrswp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"user\", user_message)\n",
        "])"
      ],
      "metadata": {
        "id": "oDgnZT2gwf7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_template = \"\"\"Can you please inspect this input and convert it to a python list for numbers realted to doctor and patient like in the example below?.\n",
        "JUST GIVE THE PYTHON LISTS AND NOTHING ELSE!\n",
        "## Example ##\n",
        "INPUT:\n",
        "1. Doctor\n",
        "2. Doctor\n",
        "3. Patient\n",
        "4. Doctor\n",
        "5. Patient\n",
        "6. Doctor\n",
        "OUTPUT:\n",
        "doctor = [1, 2, 4, 6]\n",
        "patient = [3, 5]\n",
        "\n",
        "INPUT:\n",
        "{text}\n",
        "OUTPUT:\n",
        "\"\"\"\n",
        "evalpr = ChatPromptTemplate.from_template(_template)\n",
        "eval = evalpr | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "9hTGY-emyzbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List"
      ],
      "metadata": {
        "id": "l6TkM_z8DV74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoctorPhrases(BaseModel):\n",
        "    \"\"\"Extracts the number in srt content that belongs to doctor in a doctor patient talk.\"\"\"\n",
        "    lst : List = Field(..., description=\"List of numbers in the srt file content that belongs to the doctor in a doctor patient encounter transcription.\")"
      ],
      "metadata": {
        "id": "b_ynRFzgDDfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | ChatOpenAI(temperature=0, model=\"gpt-4o\").bind_tools([DoctorPhrases], tool_choice='DoctorPhrases')"
      ],
      "metadata": {
        "id": "vH0egtyYEkS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic"
      ],
      "metadata": {
        "id": "2rsKgQ0eGFBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = prompt | ChatAnthropic(temperature=0, model=\"claude-3-5-sonnet-20241022\").bind_tools([DoctorPhrases], tool_choice='DoctorPhrases')"
      ],
      "metadata": {
        "id": "BghlaxTHGCpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_srt(file_path):\n",
        "    chunks = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        chunk = []\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line:  # Non-empty line\n",
        "                chunk.append(line)\n",
        "            else:  # Empty line indicates the end of a chunk\n",
        "                if chunk:\n",
        "                    chunks.append(\"\\n\".join(chunk))\n",
        "                    chunk = []\n",
        "        # Append the last chunk if the file doesn't end with an empty line\n",
        "        if chunk:\n",
        "            chunks.append(\"\\n\".join(chunk))\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "dy146ruBxP8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_file = \"video.srt\"\n",
        "srt_file = '/content/gdrive/MyDrive/MLprojects/osce_pipeline3/data/video4/video.srt'\n",
        "chunks = parse_srt(srt_file)"
      ],
      "metadata": {
        "id": "ObtFtFvRxRlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = chain.invoke({'srt':'\\n'.join(chunks[:10])})"
      ],
      "metadata": {
        "id": "aeCMF-uCrs1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "XHt7pHlzqhAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update SRT"
      ],
      "metadata": {
        "id": "USjRg6jG1AqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_speaker_prefix_old(srt_file, doctor_indices, patient_indices, output_file):\n",
        "    with open(srt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    updated_lines = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(lines):\n",
        "        line = lines[i].strip()\n",
        "\n",
        "        if line.isdigit():  # Start of a new SRT block (ID line)\n",
        "            index = int(line)\n",
        "            updated_lines.append(line)  # Add the ID line\n",
        "            i += 1\n",
        "\n",
        "            # Add the timestamp line\n",
        "            updated_lines.append(lines[i].strip())\n",
        "            i += 1\n",
        "\n",
        "            # Add text with the speaker prefix\n",
        "            text_lines = []\n",
        "            while i < len(lines) and lines[i].strip():\n",
        "                text_lines.append(lines[i].strip())\n",
        "                i += 1\n",
        "\n",
        "            if index in doctor_indices:\n",
        "                text_lines = [f\"Doctor: {text}\" for text in text_lines]\n",
        "            elif index in patient_indices:\n",
        "                text_lines = [f\"Patient: {text}\" for text in text_lines]\n",
        "\n",
        "            updated_lines.extend(text_lines)\n",
        "        else:\n",
        "            updated_lines.append(line)\n",
        "        i += 1\n",
        "\n",
        "    # Write the updated SRT to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(\"\\n\".join(updated_lines) + \"\\n\")"
      ],
      "metadata": {
        "id": "VU6-r5JAqhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_speaker_prefix(srt_file, doctor_indices, output_file):\n",
        "    with open(srt_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    updated_lines = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(lines):\n",
        "        line = lines[i].strip()\n",
        "\n",
        "        if line.isdigit():  # Start of a new SRT block (ID line)\n",
        "            index = int(line)\n",
        "            updated_lines.append(line)  # Add the ID line\n",
        "            i += 1\n",
        "\n",
        "            # Add the timestamp line\n",
        "            updated_lines.append(lines[i].strip())\n",
        "            i += 1\n",
        "\n",
        "            # Collect text lines\n",
        "            text_lines = []\n",
        "            while i < len(lines) and lines[i].strip():\n",
        "                text_lines.append(lines[i].strip())\n",
        "                i += 1\n",
        "\n",
        "            # Add speaker prefix\n",
        "            if index in doctor_indices:\n",
        "                text_lines = [f\"Doctor: {text}\" for text in text_lines]\n",
        "            else:  # Patient by default\n",
        "                text_lines = [f\"Patient: {text}\" for text in text_lines]\n",
        "\n",
        "            updated_lines.extend(text_lines)\n",
        "        else:\n",
        "            updated_lines.append(line)\n",
        "        i += 1\n",
        "\n",
        "    # Write the updated SRT to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(\"\\n\".join(updated_lines) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "57Vw3KlAH9mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_in_chunks_with_overlap(lst, chunk_size, window_size):\n",
        "    step = chunk_size - window_size  # Define the step to maintain overlap\n",
        "    if step <= 0:\n",
        "        raise ValueError(\"Chunk size must be greater than window size to create overlap.\")\n",
        "\n",
        "    for i in range(0, len(lst) - window_size + 1, step):\n",
        "        yield lst[i:i + chunk_size]"
      ],
      "metadata": {
        "id": "7Fvhz8qeFqxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 30  # Define the size of each chunk\n",
        "window_size = 5  # Define the overlap size"
      ],
      "metadata": {
        "id": "XxQ0qTvHFu3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doctor_lst = []"
      ],
      "metadata": {
        "id": "d1wYWo_AHBuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in iterate_in_chunks_with_overlap(chunks, chunk_size, window_size):\n",
        "    res = chain.invoke({'srt': '\\n'.join(chunk)})\n",
        "    lst = res.tool_calls[0]['args']['lst']\n",
        "    doctor_lst.extend(lst)\n",
        "    print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIz0LWmHFtoV",
        "outputId": "3b0c7444-d190-4faa-ec5a-c9fb097452ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 27, 28, 29]\n",
            "[28, 29, 30, 31, 32, 34, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
            "[52, 53, 54, 55, 56, 57, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
            "[76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105]\n",
            "[101, 102, 103, 103, 104, 104, 104, 105, 106, 106, 107, 108, 108, 109, 110, 111, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130]\n",
            "[126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doctor = sorted(list(set(doctor_lst)))"
      ],
      "metadata": {
        "id": "tYaS8tlEF0lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpK-4ptWHT0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3TJCy-UHT2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUUUSnCbHT5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = \"video_updated2.srt\"\n",
        "\n",
        "# Update the SRT file\n",
        "add_speaker_prefix(srt_file, doctor, output_file)"
      ],
      "metadata": {
        "id": "77PBFLwx2qku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"{output_file}\" \"{data_dir}\""
      ],
      "metadata": {
        "id": "KKe65mg4qhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ei-WcBsxqhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hs8GFi6zqhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verbal"
      ],
      "metadata": {
        "id": "kgYmUibDI_k0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lh3CGMOIqhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zplqI2ZoTeI8"
      },
      "outputs": [],
      "source": [
        "verbal = ['Reaches Agreement', 'Shares Information', 'Builds a Relationship',\n",
        "          'Shows Verbal Empathy', 'Provides Structure', 'Gathers Information',\n",
        "          'Provides Closure', \"Understands the Patient's Perspective\",\n",
        "          'Opens the Discussion', 'Use of Fillers vs Silence']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall = ['English Proficiency', 'Overall Impression',\n",
        "           'Use of Facial Expression', 'Use of Body Language', ]"
      ],
      "metadata": {
        "id": "vJJ5MSwUTeI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BuildsRelationship(BaseModel):\n",
        "    \"\"\"\n",
        "    Greets and shows interest in patient as a person\n",
        "    uses words that show care, respect, and non-judgment throughout interview\n",
        "    asks for permission (e.g., before asking sensitive questions or during physical examination)\n",
        "    remains attentive and professional\"\"\"\n",
        "\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether relationship building skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "A7VQu0cB8igZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OpensDiscussion(BaseModel):\n",
        "    \"\"\"\n",
        "    Allows patient to complete opening statement(s) without interruption\n",
        "    asks “Is there anything else?” (or similar) to elicit full list of concerns\n",
        "    explains and/or negotiates an agenda for rest of visit\n",
        "    \"\"\"\n",
        "\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether opening discussion skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "2zZPw24U8sZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GathersInformation(BaseModel):\n",
        "    \"\"\"Elicits patient story using open-ended questions (e.g., “Tell me about…”)\n",
        "    attentively listens and clarifies details as necessary with specific (“closed”) questions\n",
        "    explored the problem like a natural conversation as opposed to an interrogation\n",
        "    summarizes and gives patient opportunity to correct or add information\n",
        "    avoids or clearly explains any medical jargon\"\"\"\n",
        "\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether information gathering skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "rLmbCFFP8nav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnderstandsPatientPerspective(BaseModel):\n",
        "    \"\"\"\n",
        "    Elicits patient’s ideas, concerns, and expectations of the illness and treatment\n",
        "    explores how the problem affects the patient’s life,\n",
        "    encourages patient to express ideas and feelings and responds effectively\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether understanding patient's perspective skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "2KOAYO-h8qno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShowsVerbalEmpathy(BaseModel):\n",
        "    \"\"\"\n",
        "    Shows genuine interest in and concern for patient’s situation\n",
        "    identifies/labels/validates patient’s feelings and emotions\n",
        "    responds appropriately to patient’s emotional verbal cues\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether showing verbal skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "UZ3zunBf8j-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SharesInformation(BaseModel):\n",
        "    \"\"\"\n",
        "    Assesses patient’s prior knowledge and understanding of the problem and desire for more information\n",
        "    explains in small “chunks” using words that patient can understand\n",
        "    repeats information as necessary and checks for understanding\n",
        "    provides recommendations and/or pros/cons/risks as appropriate,\n",
        "    encourages patient to ask questions or bring up concerns\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether sharing information skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "MJZ16GkO8fOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReachesAgreement(BaseModel):\n",
        "    \"\"\"\n",
        "    Includes patient in decision-making to extent s/he desires\n",
        "    asks about patient’s ability to follow diagnostic and/or treatment plans\n",
        "    ensures mutual understanding of next steps and/or treatment plan provides \\\n",
        "    support by sharing additional resources as appropriate\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether reaching to agreement skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "jiQc2BJ8tJWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProvidesClosure(BaseModel):\n",
        "    \"\"\"\n",
        "    Asks whether patient has any more questions, concerns, or other issues\n",
        "    summarizes / asks patient to summarize plan and next steps\n",
        "    clarifies any follow-up or contact arrangements\n",
        "    acknowledges patient and closes interview effectively\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"Describes whether providing closure skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "8FhTTux88pdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProvidesStructure(BaseModel):\n",
        "    \"\"\"\n",
        "    Conducts the interview in a clear, logical, structured way using signposting\\\n",
        "     and transition statements to different lines of questions or parts of interview\n",
        "    manages time and pace effectively so that consultation does not feel rushed\\\n",
        "     or incomplete, nor affects rapport with patient\n",
        "    explains what will happen next and rationale if needed\n",
        "    \"\"\"\n",
        "    score: int = Field(\n",
        "        ...,\n",
        "        description=\"describes whether providing structure skills are used or not.\",\n",
        "        enum=[0, 1],\n",
        "    )"
      ],
      "metadata": {
        "id": "3BWrVFLo8ldv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [BuildsRelationship,\n",
        "GathersInformation,\n",
        "OpensDiscussion,\n",
        "ProvidesClosure,\n",
        "ProvidesStructure,\n",
        "ReachesAgreement,\n",
        "SharesInformation,\n",
        "ShowsVerbalEmpathy,\n",
        "UnderstandsPatientPerspective]"
      ],
      "metadata": {
        "id": "SfrZIfoxrmRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatAnthropic(model='claude-3-5-sonnet-20241022', temperature=0)"
      ],
      "metadata": {
        "id": "-hQs-IeKtJlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "human= \"\"\"Available tiers for this task include:\n",
        "<available_tiers>\n",
        "Reaches Agreement, Shares Information, Builds a Relationship, Shows Verbal Empathy, \\\n",
        "Provides Structure, Gathers Information, Provides Closure, Understands the Patient's Perspective, \\\n",
        "Opens the Discussion, Use of Fillers vs Silence\n",
        "</available_tiers>\n",
        "\n",
        "For each input (a phrase from doctor's talk), 1) select suitable tier(s) 2) give a binary score for selected each tier.\"\"\""
      ],
      "metadata": {
        "id": "wdvDp2hHtccr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert in medical communication skills. You will be annotating verbal communication skills in a doctor patient encounter.\"),\n",
        "    ('human', human),\n",
        "    (\"human\", \"{input}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "-S71SE6Ws7OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = prompt | llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "aIsf8mp8tJsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain.invoke({\"input\":'I understand your concerns'})"
      ],
      "metadata": {
        "id": "O7iKlp-MTgFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2tnMB9DJJEc",
        "outputId": "0cbf6838-8315-4b85-bd6a-698f4a09b68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'ShowsVerbalEmpathy',\n",
              "  'args': {'score': 1},\n",
              "  'id': 'toolu_01W9tE1NDa1eAwZ1X5ydJeA8',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r.tool_calls[0])\n",
        "print(r.tool_calls[1])\n",
        "print(r.tool_calls[2])"
      ],
      "metadata": {
        "id": "d6Ycjjk5byeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfc4e23-99ab-49ed-c0e3-80ded78e33c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'ProvidesStructure', 'args': {'score': 1}, 'id': 'toolu_01X7Jwb5zPa3nP7jcifzn558', 'type': 'tool_call'}\n",
            "{'name': 'ProvidesClosure', 'args': {'score': 1}, 'id': 'toolu_01AsKkKmWXg3LDAPaq9TnB97', 'type': 'tool_call'}\n",
            "{'name': 'SharesInformation', 'args': {'score': 1}, 'id': 'toolu_01RTzvs3EsWsFDWfESAWBPer', 'type': 'tool_call'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYufHa72qhaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_with_overlap(lst, chunk_size, window_size):\n",
        "    step = chunk_size - window_size  # Calculate the step size\n",
        "    if step <= 0:\n",
        "        raise ValueError(\"Chunk size must be greater than window size for overlap.\")\n",
        "\n",
        "    for i in range(0, len(lst), step):\n",
        "        yield i, lst[i:i + chunk_size]  # Yield the starting index and chunk"
      ],
      "metadata": {
        "id": "P_wVaI22MbTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_phrase(phrase):\n",
        "    result = chain2.invoke({\"input\": phrase})\n",
        "    l = []\n",
        "    for i in result.tool_calls:\n",
        "        l.append(i['name'])\n",
        "    phrase = f\"{phrase} [Label: {l}]\"\n",
        "    return phrase"
      ],
      "metadata": {
        "id": "_jCVAbFQNHOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 50  # Size of each chunk\n",
        "window_size = 5   # Overlap size"
      ],
      "metadata": {
        "id": "C3JtMd2lMcGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srt_text = ''"
      ],
      "metadata": {
        "id": "DOuoWCP4RbQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for start_idx, chunk in iterate_with_overlap(chunks, chunk_size, window_size):\n",
        "    # Pass the chunk to the chain to get indices of doctor phrases relative to the original list\n",
        "    res = chain1.invoke({'input': '\\n'.join(chunk)})\n",
        "    doctor_indices = res.tool_calls[0]['args']['lst']  # Indices of doctor phrases in the original list\n",
        "\n",
        "    # Apply the labeling function only to doctor phrases\n",
        "    labeled_phrases = []\n",
        "    for idx, phrase in enumerate(chunk):\n",
        "        global_idx = start_idx + idx  # Map chunk index to original list index\n",
        "        if global_idx in doctor_indices:  # Check if the global index is a doctor phrase\n",
        "            try:\n",
        "                labeled_ph = label_phrase(phrase)\n",
        "            except:\n",
        "                labeled_ph = phrase\n",
        "            labeled_phrases.append(labeled_ph)\n",
        "        else:\n",
        "            labeled_phrases.append(phrase)  # Keep the original phrase if not a doctor phrase\n",
        "\n",
        "    # Combine labeled phrases into the `srt` format\n",
        "    srt = '\\n'.join(labeled_phrases)\n",
        "    srt_text += srt + '\\n'"
      ],
      "metadata": {
        "id": "HyDq9A5uqhfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('labeled.srt', 'wt', encoding='utf-8') as f:\n",
        "    f.write(srt_text)"
      ],
      "metadata": {
        "id": "MSG-5qBvqhfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6G8VvkDjqhfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1bOe8WuIqhfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vxVumRiFqhjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L5l5g8-hqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7H-bMSrdqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "APp0DyWPqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTrwXJbmqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DarHfdz7qhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0z3cKSWMqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQjat5aCqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mi9h-5BhqhjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yGTgcRYmoudu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V3h6iXsTougU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}